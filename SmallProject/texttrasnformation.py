# -*- coding: utf-8 -*-
"""TextTrasnformation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GBhuluyHsLhYuxvlK6asIYezas4YyPiI
"""

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk
import pandas as pd
# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
reddit_data = pd.read_csv("/content/reddit_posts.csv")
reddit_data.columns = ['Post']
print(reddit_data.head())
# Define a function for text transformation
def transform_text_to_sequences(dataframe, column_name):
    stop_words = set(stopwords.words('english'))
    sequences = []

    for post in reddit_data['Post']:
        # Tokenize the post
        tokens = word_tokenize(post)
        # Remove stopwords and non-alphabetic words
        filtered_tokens = [word.lower() for word in tokens if word.isalpha() and word not in stop_words]
        sequences.append(filtered_tokens)

    return sequences

# Apply the transformation to the Reddit dataset
reddit_sequences = transform_text_to_sequences(reddit_data, 1)

# Display the first few transformed sequences
reddit_sequences[:5]
